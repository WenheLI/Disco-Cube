# Lead-Follow
Kinetic Interfaces Spring 2018 Final@NYU Shanghai

## Brief

### This is a story of a leader in the dance becomes a follower in the end.

**Lead / Follow** is a dancing-like interactive experience. It is motion tracking platform where the current user’s motion will take leads on the previous users’ motions and will be recorded to follow future users’ motions.

## Experience

First, before any user goes in front of the Kinect, on the screen the motion of previous users in point clouds joggling and moving around on their own.

When someone goes in front of the Kinect, all will **pause**. Text instructions will pop up and invite him to **take the lead** triggered by **holding his hand on his head**. Then, the user will be lead the point clouds ‘ motion in many ways by his/her motion gestures — shaking the head to change their **color palette**, moving around to move their **positions**, waving his arm to **blow** the point clouds as if wind comes, and so on. The user won’t have to deliberately make these gestures, but rather **randomly dancing** around to lead the dance party. Every small gesture in the process of the user’s dancing will affect the animation of the previous motion point clouds, which should seems **naturally** incorporated.

When the user is done with the leading, the motion point cloud of him/her will join the series of point clouds being controlled, so that the future users will be able to control his/her motion recorded by the Kinect.

## Aesthetic
The goal of the aesthetic style of the project is to have a dance club vibe. The current prototype looks like this:
![Oh no](http://s3-ap-southeast-1.amazonaws.com/ima-wp/wp-content/uploads/sites/5/2018/05/02150937/IMG_9614.jpg)
